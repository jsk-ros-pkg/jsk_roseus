<launch>
  <node name="image_siftnode" pkg="imagesift" type="imagesurf"
	output="screen" >
    <remap from="image" to="image_rect_color" />
  </node>

  <node name="point_pose_extractor" pkg="jsk_perception"
	type="point_pose_extractor">
    <param name="child_frame_name" value="opencv_logo"/>
    <param name="template_filename" value="$(find roseus_tutorials)/img/1000yen.jpg"/>
    <param name="object_width" value="0.15" />
    <param name="object_height" value="0.076" />
    <param name="reprojection_threshold" value="10.0" />  <!-- 3.0 -->
    <param name="distanceratio_threshold" value="0.60" /> <!-- 0.49 -->
	<param name="relative_pose" value="0 0 0 0 0 0 1" />    <!-- quaternion expression -->
	<!-- param name="relative_pose" value="0 0 0 0 0 0" / --> <!-- you can also use rpy expression. --> -->
    <param name="error_threshold" value="50.0" />
  </node>

  <sphinxdoc><![CDATA[
This script starts sift base object pose detection node.
defualt template image is `opencv logo <http://www.google.com/search?client=ubuntu&channel=fs&q=opencv&oe=utf-8&um=1&ie=UTF-8&tbm=isch&source=og&sa=N&hl=ja&tab=wi&biw=937&bih=638>`_.

.. code-block:: bash

  rosrun roseus_tutorial point-pose-extraction.l

to read the result data from euslisp program.
you need to launch image-view.launch before using this sample.
  ]]></sphinxdoc>

</launch>
